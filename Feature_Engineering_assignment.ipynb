{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPvmCrRNGn4ZsXc6Cvj7xF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhishekgutte200/Python_programs/blob/main/Feature_Engineering_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1. What is Parameter?"
      ],
      "metadata": {
        "id": "Z6V5PlFEGGQt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. In feature engineering, a parameter refers to a variable that governs the behavior of a feature engineering technique or a machine learning model's performance during the training process. These parameters significantly influence the transformation process applied to the data during feature extraction and model training.\n",
        "\n",
        "Here's a breakdown of their roles in each aspect:\n",
        "\n",
        "**Feature Engineering Techniques:** In techniques like feature scaling or dimensionality reduction, parameters control the transformation process.\n",
        "* For example, in **StandardScaler**, the parameter `with_mean` controls whether to center the data by subtracting the mean, and `with_std` controls whether to scale the data to unit variance.\n",
        "In PCA, the parameter `n_components` controls the number of principal components to retain.\n",
        "\n",
        "**Machine Learning Model Training:** During model training, parameters impact how the model learns from the data.\n",
        "\n",
        "* For instance, in a **linear regression model**, the coefficients (weights) assigned to each feature are parameters that the model learns during training. These parameters determine the relationship between the features and the target variable.\n",
        "* In a **decision tree model**, the maximum depth of the tree, minimum number of samples per leaf, and the splitting criterion are parameters that govern the tree's growth and complexity, affecting its predictive performance.\n",
        "In essence, feature engineering parameters are levers used to fine-tune the data transformation process and influence the overall machine learning model's behavior. Careful tuning and optimization of these parameters are crucial for achieving optimal model performance."
      ],
      "metadata": {
        "id": "AcQz2NKJGV_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2. What is Correlation?"
      ],
      "metadata": {
        "id": "Nl3cznY7I30q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In statistics, **correlation** is a statistical measure that describes the strength and direction of the relationship between two or more variables. In simpler terms, it quantifies how strongly two variables are related.\n",
        "\n",
        "\n",
        "**Strength:** It refers to how closely the variables move together.\n",
        "\n",
        "* A strong correlation indicates a clear and predictable relationship, meaning a change in one variable is likely associated with a corresponding change in the other.\n",
        "* A weak correlation suggests a less clear or less consistent relationship.\n",
        "Direction:** It indicates whether the variables move in the same or opposite directions.\n",
        "\n",
        "A positive correlation means that as one variable increases, the other tends to increase as well.\n",
        "A negative correlation means that as one variable increases, the other tends to decrease.\n",
        "Correlation Coefficient: The strength and direction of the relationship are typically measured using a correlation coefficient. The most common one is Pearson's correlation coefficient (r), which ranges from -1 to +1:\n",
        "\n",
        "A value of +1 represents a perfect positive correlation.\n",
        "A value of -1 represents a perfect negative correlation.\n",
        "A value of 0 indicates no linear correlation.\n",
        "Important Considerations:\n",
        "\n",
        "Correlation does not imply causation. Just because two variables are correlated doesn't mean one causes the other. There could be other factors influencing both variables.\n",
        "Correlation primarily measures linear relationships. If the relationship is non-linear, correlation might not accurately capture it.\n",
        "In the context of Google Colab, you can calculate correlation using libraries like NumPy, Pandas, and SciPy. Here's an example using Pandas:"
      ],
      "metadata": {
        "id": "Vki3lhYRI8Dh"
      }
    },
    {
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming you have a DataFrame named 'df' with your data\n",
        "correlation_matrix = df.corr()\n",
        "print(correlation_matrix) # To see the output, run the code"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "4tcQWNjZJ7qZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3.Define Machine Learning. What are the main components in Machine Learning?"
      ],
      "metadata": {
        "id": "kpaY3V1D4RJc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Definition:**\n",
        "\n",
        "Machine learning (ML) is a subfield of artificial intelligence (AI) that focuses on enabling computers to learn from data without being explicitly programmed. It involves the development of algorithms and models that allow systems to automatically identify patterns, make predictions, and improve their performance over time based on the data they are exposed to.\n",
        "\n",
        "**Main Components:**\n",
        "\n",
        "1. **Data:**\n",
        " * Machine learning algorithms require data to learn from.\n",
        " * This data can be in various forms, such as text, images, numbers, or sensor readings.\n",
        " * The quality and quantity of data significantly impact the performance of machine learning models.\n",
        "\n",
        "2. **Algorithms:**\n",
        "  * These are the core of machine learning.\n",
        "  * They are sets of rules or instructions that a computer follows to process data and learn patterns.\n",
        "  * Different algorithms are suited for different types of tasks, such as classification, regression, clustering, and dimensionality reduction.\n",
        "3. **Model:**\n",
        " * A model is a representation of the patterns learned by a machine learning algorithm from the data.\n",
        " * It is used to make predictions or decisions on new, unseen data.\n",
        " * The model's performance is evaluated based on its accuracy and ability to generalize to new data.\n",
        "4. **Evaluation:**\n",
        " * Evaluating the performance of a machine learning model is crucial to ensure its effectiveness.\n",
        " * Various metrics are used to assess the model's accuracy, precision, recall, and other relevant measures.\n",
        " * This evaluation helps in fine-tuning the model and selecting the best-performing one for a specific task.\n",
        "5. **Optimization:**\n",
        " * The process of improving the performance of a machine learning model by adjusting its parameters or hyperparameters.\n",
        " * This involves techniques like gradient descent, grid search, and cross-validation.\n",
        " * Optimization aims to find the optimal settings that minimize errors and maximize the model's predictive power."
      ],
      "metadata": {
        "id": "ZEW-5yy-4ms7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss Value and Model Quality**\n",
        "\n",
        "In machine learning, the loss value (or loss function) is a measure of how well a model's predictions match the actual values. It quantifies the error or discrepancy between the predicted and true values.\n",
        "\n",
        "**The lower the loss value, thebetter the model's performance.** This is because a lower loss indicates that the model is making fewer errors and its predictions are closer to the ground truth. Conversely, a higher loss value suggests that the model is making more significant errors and its predictions are less accurate.\n",
        "\n",
        "**During the training process**, the loss value is continuously monitored and used to update the model's parameters. The goal is to minimize the loss value, which leads to better model performance.\n",
        "\n",
        "**loss value is used to assess model quality:**\n",
        "\n",
        "1. **Data Splitting:** The dataset is divided into training, validation, and testing sets.\n",
        "1. **Model Training:** The model is trained using the training data, and the loss value is calculated on this data.\n",
        "1. **Validation:** The trained model is evaluated on the validation set, and its loss value is monitored. This helps in identifying potential issues like overfitting (where the model performs well on the training data but poorly on unseen data).\n",
        "1. **Hyperparameter Tuning:** Based on the validation loss, the model's hyperparameters are adjusted to improve its performance.\n",
        "1. **Testing:** Once the model is finalized, it is tested on the unseen testing data to get a final estimate of its performance. The loss value on the testing set is a key indicator of the model's overall quality.\n",
        "\n",
        "**Interpreting Loss Values**\n",
        "\n",
        "While a lower loss value generally indicates a better model, it's important to consider the following:\n",
        "\n",
        "* **Scale of Loss Values:** The absolute value of the loss may vary depending on the specific loss function used. Therefore, it's more important to focus on the relative change in loss during training and validation.\n",
        "* **Overfitting:** If the training loss decreases significantly while the validation loss starts to increase, it may indicate overfitting. This means the model is memorizing the training data rather than learning general patterns.\n",
        "* **Context:** The acceptable loss value depends on the specific problem and dataset. What might be considered a good loss value in one scenario may not be in another."
      ],
      "metadata": {
        "id": "RNWpUcG459bK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q5. What are continuous and categorical variables?"
      ],
      "metadata": {
        "id": "606BrhVQ8W2Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Continuous Variables:**\n",
        "\n",
        "* **Definition:** Continuous variables are numeric variables that can take on any value within a given range. They are measured on a continuous scale, meaning there are an infinite number of possible values between any two points.\n",
        "* **Examples:**\n",
        " * Height: Can be 175.5 cm, 162.2 cm, etc.\n",
        " * Weight: Can be 65.3 kg, 72.1 kg, etc.\n",
        " * Temperature: Can be 25.5°C, 30.2°C, etc.\n",
        " * Time: Can be 2.5 hours, 3.75 hours, etc.\n",
        "* **Characteristics:**\n",
        " * Can be measured with high precision.\n",
        " * Often represented on a number line.\n",
        " * Can be used in mathematical operations like addition, subtraction, multiplication, and division.\n",
        " * Suitable for statistical analysis methods like regression and correlation.\n",
        "\n",
        "**Categorical Variables:**\n",
        "\n",
        "* **Definition:** Categorical variables are variables that represent categories or groups. They are also known as discrete or qualitative variables. They have a limited number of distinct values or levels.\n",
        "* **Examples:**\n",
        " * Gender: Male, Female, Other\n",
        " * Color: Red, Blue, Green, Yellow\n",
        " * City: London, Paris, Tokyo, New York\n",
        " * Education Level: High School, Bachelor's, Master's, PhD\n",
        "* **Characteristics:**\n",
        " * Represent distinct categories or groups.\n",
        " * Cannot be meaningfully measured on a continuous scale.\n",
        " * Often represented using labels or codes.\n",
        " * Can be nominal (unordered) or ordinal (ordered).\n",
        " * Suitable for statistical analysis methods like chi-square tests and ANOVA.\n",
        "\n"
      ],
      "metadata": {
        "id": "hEjPSHBT8dDR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q6.How do we handle categorical variables in Machine Learning? What are the common techniques?"
      ],
      "metadata": {
        "id": "E3xlBrJY-_Gv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handling Categorical Variables in Machine Learning**\n",
        "\n",
        "Most machine learning algorithms work best with numerical data. However, many datasets contain categorical variables (e.g., gender, color, city). To use these variables in machine learning models, we need to convert them into a numerical format. This process is called encoding.\n",
        "\n",
        "**Common Techniques for Handling Categorical Variables:**\n",
        "\n",
        "1. **One-Hot Encoding:**\n",
        "\n",
        " * Creates a new binary feature for each category of the categorical variable.\n",
        " * If a data point belongs to a particular category, the corresponding binary feature is set to 1; otherwise, it's set to 0.\n",
        " * **Suitable for:** Nominal categorical variables (no inherent order) with a relatively small number of categories.\n",
        " * **Example:** If the variable \"color\" has categories \"red,\" \"blue,\" and \"green,\" one-hot encoding would create three new features: \"color_red,\" \"color_blue,\" and \"color_green.\"\n",
        "2.**Label Encoding:**\n",
        "\n",
        " * Assigns a unique integer to each category of the categorical variable.\n",
        " * **Suitable for:** Ordinal categorical variables (with an inherent order) or when the number of categories is large.\n",
        " * **Example:** If the variable \"size\" has categories \"small,\" \"medium,\" and \"large,\" label encoding might assign 0 to \"small,\" 1 to \"medium,\" and 2 to \"large.\"\n",
        "3. **Ordinal Encoding:**\n",
        "\n",
        " * Similar to label encoding but explicitly considers the order of categories.\n",
        " * **Suitable for:** Ordinal categorical variables where the order is important.\n",
        " * **Example**: If the variable \"education level\" has categories \"high school,\" \"bachelor's,\" and \"master's,\" ordinal encoding would preserve the order by assigning 0 to \"high school,\" 1 to \"bachelor's,\" and 2 to \"master's.\"\n",
        "4.**Target Encoding (Mean Encoding):**\n",
        "\n",
        "* Replaces each category with the average value of the target variable for that category.\n",
        "* **Suitable for:** High-cardinality categorical variables (many unique categories) where other encoding methods may lead to high dimensionality.\n",
        "* **Example**: If the target variable is \"income\" and the categorical variable is \"city,\" target encoding would replace each city with the average income of people living in that city.\n",
        "**Binary Encoding:**\n",
        "\n",
        "* Represents each category with a unique binary code.\n",
        "* **Suitable for:** High-cardinality categorical variables to reduce dimensionality compared to one-hot encoding.\n",
        "* **Example:** If there are 8 categories, binary encoding would use 3 bits to represent each category (2^3 = 8).\n",
        "**Frequency Encoding:**\n",
        "\n",
        " * Replaces each category with its frequency (or percentage) in the dataset.\n",
        " * **Suitable for:** Capturing the relative importance of categories based on their occurrence.\n",
        " * **Example:** If the category \"red\" appears 50 times in a dataset of 100 samples, frequency encoding would replace \"red\" with 0.5 (or 50%).\n",
        "\n",
        "**Choosing the Right Technique:**\n",
        "\n",
        "The choice of encoding technique depends on the specific dataset, the type of categorical variable, and the machine learning algorithm being used. Experimentation and evaluation are often necessary to determine the best approach for a particular task."
      ],
      "metadata": {
        "id": "olBFf6uh--9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q7. What do you mean by training and testing a dataset?"
      ],
      "metadata": {
        "id": "ce0XCgtn_WRo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**raining Dataset:**\n",
        "\n",
        "* **Purpose:** Used to train the machine learning model. This is the data the model learns from to identify patterns and relationships.\n",
        "* **Characteristics:**\n",
        " * Typically the largest portion of the dataset (e.g., 70-80%).\n",
        " * Contains both input features (independent variables) and target variables (dependent variable).\n",
        " * The model adjusts its parameters based on this data to minimize errors and improve predictions.\n",
        "**Testing Dataset:**\n",
        "\n",
        "* **Purpose:** Used to evaluate the performance of the trained model on unseen data. This helps assess how well the model generalizes to new, real-world examples.\n",
        "* **Characteristics:**\n",
        " * A smaller portion of the dataset (e.g., 20-30%).\n",
        " * Contains input features but the target variable is held out.\n",
        " * The model makes predictions on this data, and these predictions are compared to the actual target values to calculate performance metrics (e.g., accuracy, precision, recall)."
      ],
      "metadata": {
        "id": "_rjbjV_q4cf7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q8. What is sklearn.preprocessing?"
      ],
      "metadata": {
        "id": "6etLJslsClzl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**sklearn.preprocessing**\n",
        "\n",
        "In scikit-learn (sklearn), the preprocessing module provides several common utility functions and transformer classes to change raw feature vectors into a representation that is more suitable for the downstream estimators.\n",
        "\n",
        "**Purpose:**\n",
        "\n",
        "The main purpose of preprocessing is to transform data into a format that improves the performance and accuracy of machine learning models. This is often necessary because raw data may have various issues that can negatively impact model training, such as:\n",
        "\n",
        "* **Different scales**: Features may have vastly different ranges (e.g., age in years vs. income in dollars).\n",
        "* **Categorical data:** Many algorithms require numerical input, so categorical features need to be converted.\n",
        "* **Missing values:** Data may have missing values that need to be handled.\n",
        "* **Outliers:** Extreme values can skew the model's learning process.\n",
        "\n",
        "**Commonly Used Classes and Functions:**\n",
        "\n",
        "* **Standardization:**\n",
        " * `StandardScaler`: Transforms data to have zero mean and unit variance.\n",
        "\n",
        "* **Normalization:**\n",
        "\n",
        " * `MinMaxScaler`: Scales data to a given range (e.g., between 0 and 1\n",
        "\n",
        " * `Normalizer`: Scales individual samples to have unit norm.\n",
        "\n",
        "**Encoding Categorical Features:**\n",
        "\n",
        " * `OneHotEncoder`: Creates binary features for each category.\n",
        " * `OrdinalEncoder`: Assigns integers to categories based on their order.\n",
        "* `LabelEncoder`: Assigns integers to categories without considering order.\n",
        "\n"
      ],
      "metadata": {
        "id": "2HfjEzE6C7kd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q9. What is a Test set?"
      ],
      "metadata": {
        "id": "tj7MSTRbGrHa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A test set, also known as a test dataset or evaluation set, is a collection of data used to evaluate the performance of a machine learning model or algorithm after it has been trained.\n",
        "\n",
        "The test set is typically a separate dataset from the training set, which is used to train the model. The test set is used to assess the model's ability to generalize to new, unseen data and to estimate its performance in real-world scenarios.\n",
        "\n",
        "**The test set serves several purposes:**\n",
        "\n",
        "1. **Evaluation:** It provides an unbiased evaluation of the model's performance.\n",
        "2. **Hyperparameter tuning:** It helps to tune hyperparameters, such as learning rate or regularization strength.\n",
        "3. **Model selection:** It allows comparing the performance of different models or algorithms.\n",
        "4. **Error estimation:** It provides an estimate of the model's error rate or performance metrics, such as accuracy, precision, recall, or F1-score.\n",
        "\n",
        "**A good test set should have the following characteristics:**\n",
        "\n",
        "1. **Independence:** It should be independent of the training set.\n",
        "2. **Representativeness:** It should be representative of the population or problem being modeled.\n",
        "3. **Size:** It should be large enough to provide reliable estimates of the model's performance.\n",
        "4. **Quality:** It should be of high quality, with accurate and relevant labels or responses."
      ],
      "metadata": {
        "id": "d6Oo60EWG1ET"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q10. How do we split data for model fitting (training and testing) in Python?How do you approach a Machine Learning problem?"
      ],
      "metadata": {
        "id": "_nWJsKXRL9y3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to Split Data for Model Fitting (Training and Testing) in Python\n",
        "\n",
        "Import necessary libraries:"
      ],
      "metadata": {
        "id": "sJF-24jvMx_f"
      }
    },
    {
      "source": [
        "import pandas as pd\n",
        "   from sklearn.model_selection import train_test_split"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "mJ1BXYrBMzDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Load your dataset:**"
      ],
      "metadata": {
        "id": "yutRrIvYM30O"
      }
    },
    {
      "source": [
        "data = pd.read_csv('your_dataset.csv')  # Replace 'your_dataset.csv' with your file path"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ls22AU_WM-9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Separate features(X) and target(y):**"
      ],
      "metadata": {
        "id": "MEg-E9GRM_mo"
      }
    },
    {
      "source": [
        "X = data[['feature1', 'feature2', ...]]  # Select your feature columns\n",
        "   y = data['target_variable']  # Select your target variable column"
      ],
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "lmN0QmdBNKBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Split the data:**"
      ],
      "metadata": {
        "id": "sP0gplYMNK4-"
      }
    },
    {
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "4S6YxuANNPb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **How to Approach a Machine Learning Problem**\n",
        "\n",
        "1. **Define the problem:** Clearly understand the problem you're trying to solve and the type of machine learning task (e.g., classification, regression, clustering).\n",
        "1. **Gather and prepare data:** Collect the necessary data, clean it, handle missing values, and perform feature engineering if needed.\n",
        "1. **Choose a model:** Select an appropriate machine learning model based on the problem type and data characteristics.\n",
        "1. **Train the model:** Use the training data to train the selected model, adjusting its parameters to optimize performance.\n",
        "1. **Evaluate the model:1.** Use the testing data to evaluate the model's performance and identify areas for improvement.\n",
        "1. **Fine-tune and iterate:1.** Adjust hyperparameters, try different models, or refine data preprocessing to improve performance.\n",
        "1. **Deploy and monitor:1.** Deploy the model to a production environment and monitor its performance over time."
      ],
      "metadata": {
        "id": "H6KMxSUMNUAu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q11. Why do we have to perform EDA before fitting a model to the data?"
      ],
      "metadata": {
        "id": "RnRXX4GEOeB3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why Perform EDA Before Model Fitting?**\n",
        "\n",
        "EDA is a crucial step in the machine learning workflow that involves analyzing and visualizing data to gain insights, identify patterns, and understand the underlying structure of the dataset. Performing EDA before model fitting is essential for several reasons:\n",
        "\n",
        "1. **Data Understanding:**\n",
        "\n",
        " * EDA helps you understand the distribution, characteristics, and relationships between variables in your data. This understanding is crucial for selecting appropriate models and features.\n",
        " * You can identify potential issues like missing values, outliers, or inconsistencies that may need to be addressed before model training.\n",
        "2. **Feature Engineering:**\n",
        "\n",
        " * EDA can reveal potential features or transformations that can improve model performance.\n",
        " * By visualizing relationships between variables, you can identify new features to create or existing features to modify.\n",
        "3. **Model Selection:**\n",
        "\n",
        " * EDA helps you choose the most suitable model for your data.\n",
        " * By understanding the data's structure and relationships, you can select models that are appropriate for the task (e.g., classification, regression) and the data type (e.g., continuous, categorical).\n",
        "4. **Data Cleaning and Preprocessing:**\n",
        "\n",
        " * EDA can identify data quality issues like missing values, outliers, or inconsistencies that need to be addressed before model training.\n",
        " * You can apply appropriate data cleaning and preprocessing techniques based on the insights gained from EDA.\n",
        "5. **Avoiding Bias and Errors:**\n",
        "\n",
        " * EDA can help you identify potential biases or errors in your data that could lead to inaccurate model predictions.\n",
        " * By understanding the data's limitations and potential biases, you can take steps to mitigate their impact on the model.\n",
        "6. **Improved Model Performance:**\n",
        "\n",
        " * By performing EDA, you can gain insights that lead to better feature engineering, model selection, and data preprocessing, ultimately improving the performance of your machine learning model.\n",
        "\n",
        "**In summary, EDA is a critical step that helps you understand your data, identify potential issues, and make informed decisions about model selection, feature engineering, and data preprocessing. This leads to more accurate, reliable, and robust machine learning models.**"
      ],
      "metadata": {
        "id": "UO7A454iO97F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q12. How can you find correlation between variables in Python?"
      ],
      "metadata": {
        "id": "m9uPBNr2QKzt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Python, you can find the correlation between variables using the corr() function from the pandas library or the corrcoef() function from the NumPy library.\n",
        "\n",
        "Here are some examples:\n",
        "\n",
        "**Using pandas**\n"
      ],
      "metadata": {
        "id": "ThVYe4SFSes7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame\n",
        "data = {'A': [1, 2, 3, 4, 5],\n",
        "        'B': [2, 3, 5, 7, 11]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate the correlation between columns\n",
        "correlation = df['A'].corr(df['B'])\n",
        "\n",
        "print(correlation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRBrpMXsLzgn",
        "outputId": "16eeaf69-1f10-4ef9-b77f-1827fe1fe69f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9722718241315028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using NumPy**"
      ],
      "metadata": {
        "id": "SB2JG1p3TX3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create two arrays\n",
        "A = np.array([1, 2, 3, 4, 5])\n",
        "B = np.array([2, 3, 5, 7, 11])\n",
        "\n",
        "# Calculate the correlation coefficient\n",
        "correlation_coefficient = np.corrcoef(A, B)\n",
        "\n",
        "print(correlation_coefficient)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0gaK5UBTdP0",
        "outputId": "75d825e7-6aaa-4be1-806e-f8cf15505243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.         0.97227182]\n",
            " [0.97227182 1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using seaborn and matplotlib for visualization**"
      ],
      "metadata": {
        "id": "E6PtjToVTh7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a DataFrame\n",
        "data = {'A': [1, 2, 3, 4, 5],\n",
        "        'B': [2, 3, 5, 7, 11]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Create a scatter plot with regression line\n",
        "sns.regplot(x='A', y='B', data=df)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "b5ct0nNeTqTS",
        "outputId": "f3eaa737-a033-4ac2-a4d1-91464f354cea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13. What is causation? Explain difference between correlation and causation with an example."
      ],
      "metadata": {
        "id": "amve8EE-T2ca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Causation**\n",
        "\n",
        "Causation refers to the relationship between two events or variables where one event (the cause) leads to the occurrence of the other event (the effect). In other words, causation implies that one variable directly influences the other variable.\n",
        "\n",
        "**Correlation**\n",
        "\n",
        "Correlation, on the other hand, refers to the statistical relationship between two variables. When two variables are correlated, it means that as one variable changes, the other variable also tends to change in a predictable way. However, correlation does not necessarily imply causation.\n",
        "\n",
        "**Difference between Correlation and Causation**\n",
        "\n",
        "To illustrate the difference between correlation and causation, consider the following example:\n",
        "\n",
        "**Example:** Ice Cream Sales and Number of People Wearing Shorts\n",
        "\n",
        "Suppose we collect data on the number of people wearing shorts and the number of ice cream sales in a city over a period of time. We might find a strong positive correlation between the two variables, i.e., as the number of people wearing shorts increases, the number of ice cream sales also tends to increase.\n",
        "\n",
        "However, this correlation does not necessarily imply causation. It's unlikely that wearing shorts directly causes people to buy more ice cream. Instead, there might be a third variable, such as temperature, that is driving both the increase in people wearing shorts and the increase in ice cream sales.\n",
        "\n",
        "In this example, the correlation between ice cream sales and people wearing shorts is due to a common underlying factor (temperature), rather than a direct causal relationship between the two variables.\n",
        "\n",
        "**Key differences between correlation and causation:**\n",
        "\n",
        "- Correlation implies a statistical relationship, while causation implies a direct influence.\n",
        "- Correlation does not necessarily imply causation, while causation implies correlation.\n",
        "- Causation requires a clear mechanism or underlying process that explains how one variable affects the other.\n",
        "\n",
        "In summary, correlation is a statistical concept that describes the relationship between two variables, while causation implies a direct influence or cause-and-effect relationship between the variables."
      ],
      "metadata": {
        "id": "zehOjLZ3UbYa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 14. What is an Optimizer? What are different types of optimizers? Explain each with an example"
      ],
      "metadata": {
        "id": "tAkZiXaVUzoS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is an Optimizer?\n",
        "\n",
        "An optimizer is an algorithm used to minimize or maximize a function, typically a loss function or an objective function, in machine learning and deep learning. The goal of an optimizer is to adjust the model's parameters to achieve the best possible performance.\n"
      ],
      "metadata": {
        "id": "cN5pRPacVAf6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Types of Optimizers\n",
        "\n",
        "Here are some common types of optimizers, along with examples:\n",
        "\n",
        "1. Gradient Descent (GD)\n",
        "\n",
        "Gradient Descent is an optimization algorithm that uses the gradient of the loss function to update the model's parameters. The gradient points in the direction of the steepest ascent, so GD moves in the opposite direction to minimize the loss.\n",
        "\n",
        "Example:\n"
      ],
      "metadata": {
        "id": "goelU-EdVXZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the loss function\n",
        "def loss(w, x, y):\n",
        "    return np.mean((w * x - y) ** 2)\n",
        "\n",
        "# Initialize the model parameter\n",
        "w = 0.5\n",
        "\n",
        "# Define the learning rate\n",
        "lr = 0.01\n",
        "\n",
        "# Define the training data\n",
        "x = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([2, 3, 5, 7, 11])\n",
        "\n",
        "# Train the model using GD\n",
        "for i in range(1000):\n",
        "    # Compute the gradient\n",
        "    gradient = np.mean(2 * (w * x - y) * x)\n",
        "\n",
        "    # Update the model parameter\n",
        "    w -= lr * gradient\n",
        "\n",
        "print(\"Optimized parameter:\", w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5j0yFEwLTyle",
        "outputId": "d69fa83f-ce5c-4416-b8c7-a08a82b89521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized parameter: 1.927272727272727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Stochastic Gradient Descent (SGD)\n",
        "\n",
        "Stochastic Gradient Descent is a variant of GD that uses a single training example to compute the gradient, rather than the entire training set.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "zMcbqoHeVry6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the loss function\n",
        "def loss(w, x, y):\n",
        "    return (w * x - y) ** 2\n",
        "\n",
        "# Initialize the model parameter\n",
        "w = 0.5\n",
        "\n",
        "# Define the learning rate\n",
        "lr = 0.01\n",
        "\n",
        "# Define the training data\n",
        "x = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([2, 3, 5, 7, 11])\n",
        "\n",
        "# Train the model using SGD\n",
        "for i in range(1000):\n",
        "    # Select a random training example\n",
        "    idx = np.random.randint(0, len(x))\n",
        "    x_batch = x[idx]\n",
        "    y_batch = y[idx]\n",
        "\n",
        "    # Compute the gradient\n",
        "    gradient = 2 * (w * x_batch - y_batch) * x_batch\n",
        "\n",
        "    # Update the model parameter\n",
        "    w -= lr * gradient\n",
        "\n",
        "print(\"Optimized parameter:\", w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H22zx-jDVvJp",
        "outputId": "3dd4b6d5-2fef-47de-9710-c6197ba8f725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized parameter: 1.8142473079975063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Momentum\n",
        "\n",
        "Momentum is an optimization algorithm that adds a fraction of the previous update to the current update, to help escape local minima.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "95mFUBDrVyZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the loss function\n",
        "def loss(w, x, y):\n",
        "    return np.mean((w * x - y) ** 2)\n",
        "\n",
        "# Initialize the model parameter\n",
        "w = 0.5\n",
        "\n",
        "# Define the learning rate\n",
        "lr = 0.01\n",
        "\n",
        "# Define the momentum coefficient\n",
        "momentum = 0.9\n",
        "\n",
        "# Initialize the previous update\n",
        "prev_update = 0\n",
        "\n",
        "# Define the training data\n",
        "x = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([2, 3, 5, 7, 11])\n",
        "\n",
        "# Train the model using Momentum\n",
        "for i in range(1000):\n",
        "    # Compute the gradient\n",
        "    gradient = np.mean(2 * (w * x - y) * x)\n",
        "\n",
        "    # Compute the update\n",
        "    update = lr * gradient + momentum * prev_update\n",
        "\n",
        "    # Update the model parameter\n",
        "    w -= update\n",
        "\n",
        "    # Update the previous update\n",
        "    prev_update = update\n",
        "\n",
        "print(\"Optimized parameter:\", w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwUpyvweV5_7",
        "outputId": "332d305d-5364-4944-e3aa-a0435f28dfe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized parameter: 1.9272727272727272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Nesterov Accelerated Gradient (NAG)\n",
        "\n",
        "NAG is an optimization algorithm that modifies the Momentum update rule to incorporate a \"lookahead\" term, which helps to escape local minima.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "nbj0USqlV64a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the loss function\n",
        "def loss(w, x, y):\n",
        "    return np.mean((w * x - y) ** 2)\n",
        "\n",
        "# Initialize the model parameter\n",
        "w = 0.5\n",
        "\n",
        "# Define the learning rate\n",
        "lr = 0.01\n",
        "\n",
        "# Define the momentum coefficient\n",
        "momentum = 0.9\n",
        "\n",
        "# Initialize the previous update\n",
        "prev_update = 0\n",
        "\n",
        "# Define the training data\n",
        "x = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([2, 3, 5, 7, 11])\n",
        "\n",
        "# Train the model using NAG\n",
        "for i in range(1000):\n",
        "    # Compute the gradient\n",
        "    gradient = np.mean(2 * (w * x))"
      ],
      "metadata": {
        "id": "2mHacGOPV-Cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 15. What is sklearn.linear_model ?"
      ],
      "metadata": {
        "id": "i_GbjsahWXrZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**sklearn.linear_model**\n",
        "\n",
        "In scikit-learn (sklearn), the linear_model module provides a set of classes and functions for implementing various linear models for regression and classification tasks.\n",
        "\n",
        "**Purpose:**\n",
        "\n",
        "Linear models are a fundamental class of machine learning algorithms that assume a linear relationship between the input features and the target variable. They are widely used for their simplicity, interpretability, and efficiency.\n",
        "\n",
        "**Commonly Used Classes:**\n",
        "\n",
        "* **Linear Regression:**\n",
        "  * LinearRegression: Ordinary least squares linear regression.\n",
        "* **Logistic Regression:**\n",
        "  * `LogisticRegression:`     \n",
        " * Logistic regression for binary and multi-class classification.\n",
        "* **Regularized Linear Models:**\n",
        "  * `Ridge:` Linear regression with L2 regularization.\n",
        "  * `Lasso:` Linear regression with L1 regularization.\n",
        "  * `ElasticNet:` Linear regression with a combination of L1 and L2 regularization.\n",
        "* **Other Linear Models:**\n",
        "  * `SGDRegressor:` Linear regression using stochastic gradient descent.\n",
        "  * `SGDClassifier:` Linear classifiers (SVM, logistic regression) using stochastic gradient descent.\n",
        "  * `Perceptron:` A simple linear classifier.\n",
        "  * `PassiveAggressiveClassifier:` A family of online learning algorithms for classification.\n",
        "\n",
        "**Benefits of Using sklearn.linear_model:**\n",
        "\n",
        "* **Simplicity and Interpretability:** Linear models are relatively easy to understand and interpret, making them a good choice for tasks where transparency is important.\n",
        "* **Efficiency:** They are computationally efficient, especially for large datasets.\n",
        "* **Wide Applicability:** Linear models can be applied to a variety of regression and classification problems.\n",
        "\n",
        "**Example Usage:**"
      ],
      "metadata": {
        "id": "Pz716Uk0WwvY"
      }
    },
    {
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Create a LinearRegression object\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit the model to the data\n",
        "model.fit(X_train, y_train) # To see the output, run the code\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test) # To see the output, run the code"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "FhxaUVHkY0NI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lr-l154kY2Ld"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BqanA09NWVHw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}